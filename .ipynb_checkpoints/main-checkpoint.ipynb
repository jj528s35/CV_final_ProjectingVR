{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import roypy\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time\n",
    "import queue\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "from PIL import Image, ImageDraw\n",
    "from sample_camera_info import print_camera_info\n",
    "from roypy_sample_utils import CameraOpener, add_camera_opener_options\n",
    "\n",
    "# 調整np.array輸出格式\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener(roypy.IDepthDataListener):\n",
    "\n",
    "    def __init__(self, z_queue, gray_queue, points3D_queue, ConfidenceIndex_queue, Confidence_queue, undistortImage=False):\n",
    "        super(MyListener, self).__init__()\n",
    "        self.z_queue = z_queue\n",
    "        self.gray_queue = gray_queue\n",
    "        self.points3D_queue = points3D_queue\n",
    "        self.ConfidenceIndex_queue = ConfidenceIndex_queue\n",
    "        self.Confidence_queue = Confidence_queue\n",
    "        self.undistortImage = undistortImage\n",
    "        self.cameraMatrix = None\n",
    "        self.distortionCoefficients = None\n",
    "\n",
    "    def onNewData(self, data):\n",
    "        zvalues = []\n",
    "        xvalues = []\n",
    "        yvalues = []\n",
    "        grayvalues = []\n",
    "        points3D = []\n",
    "        ConfidenceIndexvalues = [] # whether the pixel measured a valid 3D value\n",
    "        Confidencevalue = []\n",
    "        for i in range(data.getNumPoints()):\n",
    "            zvalues.append(data.getZ(i))\n",
    "            xvalues.append(data.getX(i))\n",
    "            yvalues.append(data.getY(i))\n",
    "            grayvalues.append(data.getGrayValue(i))\n",
    "            \n",
    "            Confidencevalue.append(data.getDepthConfidence(i))\n",
    "            if data.getDepthConfidence(i) > 0:\n",
    "                ConfidenceIndexvalues.append(i)\n",
    "            \n",
    "        zarray = np.asarray(zvalues)\n",
    "        z = zarray.reshape (-1, data.width)        \n",
    "        self.z_queue.put(z)\n",
    "        \n",
    "        xarray = np.asarray(xvalues)\n",
    "        x = xarray.reshape (-1, data.width)\n",
    "        \n",
    "        yarray = np.asarray(yvalues)\n",
    "        y = yarray.reshape (-1, data.width)\n",
    "        \n",
    "        points3D = np.dstack((x,y,z))\n",
    "        self.points3D_queue.put(points3D)\n",
    "        \n",
    "        \n",
    "        grayarray = np.asarray(grayvalues)\n",
    "        q = grayarray.reshape (-1, data.width)        \n",
    "        self.gray_queue.put(q)\n",
    "        \n",
    "        Confidencearray = np.asarray(Confidencevalue)\n",
    "        Confidence = Confidencearray.reshape (-1, data.width)\n",
    "        self.Confidence_queue.put(Confidence)\n",
    "        #ConfidenceIndex_queue\n",
    "        ConfidenceIndex = np.asarray(ConfidenceIndexvalues)\n",
    "        self.ConfidenceIndex_queue.put(ConfidenceIndex)\n",
    "\n",
    "    def paint(self, data, name,isGray = False):\n",
    "        \"\"\"\n",
    "        Called in the main thread, with data containing one of the items that was added to the queue in onNewData\n",
    "        :param data:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # create a figure and show the raw data\n",
    "        plt.figure(1)\n",
    "        if isGray == False:\n",
    "            plt.imshow(data),plt.title(name),plt.axis('off')\n",
    "        else: \n",
    "            plt.imshow(data,plt.cm.gray),plt.title(name),plt.axis('off')\n",
    "\n",
    "        plt.show(block=False)\n",
    "        plt.draw()\n",
    "\n",
    "        # this pause is needed to ensure the drawing for some backends\n",
    "        plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracker Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_event(z_queue, gray_queue, points3D_queue, ConfidenceIndex_queue, Confidence_queue, painter=None, seconds=150):\n",
    "    First = True\n",
    "    # create a loop that will run for the given amount of time\n",
    "    t_end = time.time() + seconds\n",
    "    while time.time() < t_end:\n",
    "        try:\n",
    "            # try to retrieve an item from the queue\n",
    "            # this will block until an item can be retrieved\n",
    "            # or the timeout of 1 second is hit\n",
    "\n",
    "            zImage = z_queue.get(True) if z_queue else None\n",
    "            grayImage_int32 = gray_queue.get(True) if gray_queue else None\n",
    "            points3D = points3D_queue.get(True) if points3D_queue else None\n",
    "            ConfidenceIndex = ConfidenceIndex_queue.get(True) if ConfidenceIndex_queue else None\n",
    "            Confidence = Confidence_queue.get(True) if Confidence_queue else None\n",
    "        except queue.Empty:\n",
    "            # this will be thrown when the timeout is hit\n",
    "            break\n",
    "            # break\n",
    "        else:\n",
    "            if First == True:\n",
    "                #RANSAM to get surface plane\n",
    "                surface_plane, depthImg, plane_mask = RANSAM(points3D, ConfidenceIndex, ransac_iteration = 500, inliner_threshold = 0.01)\n",
    "                First = False\n",
    "            else:\n",
    "                #\n",
    "                depthImg = get_depth_map(points3D, surface_plane)\n",
    "                #Canny edge map(infrared image) + threshold based edge map(depth image)\n",
    "                Cannyedges, Threshold_based_edge, Edge_map, grayImage = get_edge_map(grayImage_int32, depthImg)\n",
    "                #Get hight region by Hight and record its position\n",
    "                High_region_Image, high_region_list = get_high_region(depthImg)\n",
    "                #Get Hand mask by Flood fill from high region position with Edge map\n",
    "                Hand_mask_Image = get_Hand_mask(Edge_map, high_region_list, High_region_Image)\n",
    "                #\n",
    "                cnt, contours_image, hand_center, fingertips = find_fingertip(Hand_mask_Image)\n",
    "                # tracking user hand and fingertips\n",
    "                hand_tracking(hand_center, fingertips)\n",
    "                \n",
    "                # \n",
    "                \n",
    "                #Show original image and result image\n",
    "#                 painter.paint(grayImage_int32,'Gray Image',True)\n",
    "#                 painter.paint(depthImg,'Depth')\n",
    "#                 painter.paint(Cannyedges,'Canny Edges',True)\n",
    "#                 painter.paint(Threshold_based_edge,'Threshold_based Edge',True)\n",
    "                painter.paint(Edge_map,'Edge map',True)\n",
    "#                 painter.paint(High_region_Image,'High region Image',True)\n",
    "                painter.paint(Hand_mask_Image,'Hand mask Image',True)\n",
    "                painter.paint(contours_image,'Contours Image',True)\n",
    "    \n",
    "            \n",
    "#             #Store Image\n",
    "#             IsStore = False\n",
    "#             if IsStore == True:\n",
    "#                 matplotlib.image.imsave('zImage.png', zImage)\n",
    "#                 matplotlib.image.imsave('grayImage_int32.png', grayImage_int32)\n",
    "#                 matplotlib.image.imsave('points3D.png', points3D)\n",
    "#                 matplotlib.image.imsave('Confidence.png', Confidence)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANSAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Plane(sampts):\n",
    "    \"\"\"\n",
    "    Compute the equation of the plane\n",
    "    \"\"\"\n",
    "    p1 = sampts[0]\n",
    "    p2 = sampts[1]\n",
    "    p3 = sampts[2]\n",
    "    \n",
    "    a = ( (p2[1]-p1[1])*(p3[2]-p1[2])-(p2[2]-p1[2])*(p3[1]-p1[1]) )\n",
    "    b = ( (p2[2]-p1[2])*(p3[0]-p1[0])-(p2[0]-p1[0])*(p3[2]-p1[2]) )\n",
    "    c = ( (p2[0]-p1[0])*(p3[1]-p1[1])-(p2[1]-p1[1])*(p3[0]-p1[0]) )\n",
    "    d = ( 0-(a*p1[0]+b*p1[1]+c*p1[2]) )\n",
    "    \n",
    "    return a,b,c,d\n",
    "\n",
    "def Dis_pt2plane(pts, a, b, c, d):\n",
    "    \"\"\"\n",
    "    Compute the distance from points to the plane\n",
    "    \"\"\"\n",
    "    normal = math.sqrt(a*a+b*b+c*c)\n",
    "    if normal == 0:\n",
    "        normal = 1\n",
    "    \n",
    "    v = np.array([a,b,c])\n",
    "    dis = abs(np.dot(pts,v.T)+d)/normal\n",
    "    return dis\n",
    "\n",
    "def Random3points(points3D, ConfidenceIndex):\n",
    "    \"\"\"\n",
    "    Random choose 3 Confidence points\n",
    "    \"\"\"\n",
    "    sample_number = 3\n",
    "    sample_point_index = random.sample(range(ConfidenceIndex.shape[0]), sample_number)\n",
    "    sample_points = np.zeros((sample_number,3))\n",
    "    for i in range(sample_number):\n",
    "        Confidence_point_index = sample_point_index[i]\n",
    "        index = ConfidenceIndex[Confidence_point_index]\n",
    "        y = index // points3D.shape[1]\n",
    "        x = index % points3D.shape[1]\n",
    "        sample_points[i] = points3D[y][x]\n",
    "    return sample_points\n",
    "\n",
    "# def Random3points(points3D):\n",
    "#     sample_number = 3\n",
    "#     sample_point_index = random.sample(range(points3D.shape[0]*points3D.shape[1]), sample_number)\n",
    "#     sample_points = np.zeros((sample_number,3))\n",
    "#     for i in range(sample_number):\n",
    "#         index = sample_point_index[i]\n",
    "#         y = index // points3D.shape[1]\n",
    "#         x = index % points3D.shape[1]\n",
    "#         sample_points[i] = points3D[y][x]\n",
    "#     return sample_points\n",
    "\n",
    "def get_inliner_num(points3D,a,b,c,d,inliner_threshold):\n",
    "    \"\"\"\n",
    "    Compute the liner points which distance to plane < threshold\n",
    "    Also get distance from points to the plane (new Depth Image which re-project depth pixels in surface plane)\n",
    "    \"\"\"\n",
    "    inliner_num = 0\n",
    "    \n",
    "    dist = Dis_pt2plane(points3D,a,b,c,d)\n",
    "    inliner_mask = dist < inliner_threshold\n",
    "    inliner_num = np.sum(inliner_mask)\n",
    "    return inliner_num, inliner_mask, dist\n",
    "\n",
    "def RANSAM(points3D, ConfidenceIndex, ransac_iteration = 1000, inliner_threshold = 0.01):\n",
    "    best_inlinernum = -1\n",
    "    best_inlinernum = 0\n",
    "    best_plane = np.zeros((1,4))\n",
    "    best_depthImage = np.zeros((points3D.shape[0],points3D.shape[1]))\n",
    "    best_plane_mask = np.zeros((points3D.shape[0],points3D.shape[1]))\n",
    "#     best_sampts = np.zeros((3,3))\n",
    "    \n",
    "#     print(points3D.shape,points3D[80:90,110])\n",
    "    for i in range(ransac_iteration):\n",
    "        sampts = Random3points(points3D, ConfidenceIndex)\n",
    "        a,b,c,d = get_Plane(sampts)\n",
    "        \n",
    "        inliner_num, inliner_mask, depthImage = get_inliner_num(points3D,a,b,c,d,inliner_threshold)\n",
    "        if(inliner_num > best_inlinernum):\n",
    "            best_inlinernum = inliner_num\n",
    "            best_plane = np.array([a,b,c,d])\n",
    "            best_plane_mask = inliner_mask\n",
    "            best_depthImage = depthImage\n",
    "#             best_sampts = sampts\n",
    "            \n",
    "    print(\"Inliner Number\\n\", best_inlinernum)\n",
    "    print(\"Inliner plane\\n\", best_plane)\n",
    "    return best_plane, best_depthImage, best_plane_mask\n",
    "\n",
    "# ptset = np.array(([0, 0, 0],\n",
    "#             [1, 2, 0],\n",
    "#             [2, 2, 0]))\n",
    "# a,b,c,d = get_Plane(ptset)\n",
    "# pts = np.zeros((2,2,3))\n",
    "# pts[0,0] = np.array([0, 0, 1])\n",
    "# pts[0,1] = np.array([0, 0, 2])\n",
    "# pts[1,0] = np.array([0, 0, 3])\n",
    "# pts[1,1] = np.array([0, 0, 4])\n",
    "# z = Dis_pt2plane(pts,a,b,c,d)\n",
    "# print(z,z.shape)\n",
    "# get_inliner_num(pts,a,b,c,d,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_map(points3D,plane):\n",
    "    \"\"\"\n",
    "    Compute the liner points which distance to plane < threshold\n",
    "    Also get distance from points to the plane (new Depth Image which re-project depth pixels in surface plane)\n",
    "    \"\"\"\n",
    "    dist = Dis_pt2plane(points3D,plane[0],plane[1],plane[2],plane[3])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_map(grayImage,depthImage):\n",
    "    \"\"\"\n",
    "    Canny Edge map\n",
    "    turn grayImg from int32 to int8\n",
    "    blur the grayImg then do Canny Edge\n",
    "    \"\"\"\n",
    "    low_threshold = 1\n",
    "    high_threshold = 8\n",
    "    grayimg_int8 = cv2.convertScaleAbs(grayImage, alpha=(255.0/65535.0))\n",
    "    \n",
    "    kernel_size = 3\n",
    "    blur_gray = cv2.GaussianBlur(grayimg_int8,(kernel_size, kernel_size), 0)\n",
    "    Cannyedges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "    \n",
    "    \"\"\"\n",
    "    Threshold based Edge map\n",
    "    if depth between the pixel and its nearby pixels > near_depth_threshold, then labeled it\n",
    "    \"\"\"\n",
    "    near_depth_threshold = 0.05\n",
    "#     print(\"sum\",np.sum(depthImage > near_depth_threshold))\n",
    "    Threshold_based_edge = np.zeros((depthImage.shape[0],depthImage.shape[1]))\n",
    "    for y in range(1,depthImage.shape[0]-1):\n",
    "        for x in range(1,depthImage.shape[1]-1):\n",
    "            near1 = abs(depthImage[y,x] - depthImage[y-1,x-1]) > near_depth_threshold\n",
    "            near2 = abs(depthImage[y,x] - depthImage[y-1,x]) > near_depth_threshold\n",
    "            near3 = abs(depthImage[y,x] - depthImage[y-1,x+1]) > near_depth_threshold\n",
    "            near4 = abs(depthImage[y,x] - depthImage[y,x-1]) > near_depth_threshold\n",
    "            near5 = abs(depthImage[y,x] - depthImage[y,x+1]) > near_depth_threshold\n",
    "            near6 = abs(depthImage[y,x] - depthImage[y+1,x-1]) > near_depth_threshold\n",
    "            near7 = abs(depthImage[y,x] - depthImage[y+1,x]) > near_depth_threshold\n",
    "            near8 = abs(depthImage[y,x] - depthImage[y+1,x+1]) > near_depth_threshold\n",
    "            \n",
    "            labeled_it = near1 or near2 or near3 or near4 or near5 or near6 or near7 or near8\n",
    "            Threshold_based_edge[y,x] = labeled_it\n",
    "    \"\"\"\n",
    "    Merge Canny Edge map and Threshold based Edge map\n",
    "    \"\"\"\n",
    "#     Edge_map = np.logical_and(Cannyedges,Threshold_based_edge)\n",
    "    Edge_map = np.logical_or(Cannyedges,Threshold_based_edge)\n",
    "    \n",
    "    return Cannyedges,Threshold_based_edge, Edge_map, blur_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find High Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_region(depthImage):\n",
    "    \"\"\"\n",
    "    Define plane edge\n",
    "    High region : > 0.04 \n",
    "    ==> Flood fill mask : if pixels value > 0.04, then its value of mask image = 0 \n",
    "    ==> mask = depthImage < 0.04\n",
    "    \n",
    "    Next, reject the region which dose not connet with plane edge and record its position\n",
    "    ==>Just do Flood fill around the plane edge\n",
    "    \"\"\"\n",
    "    h, w = depthImage.shape[:2]\n",
    "    high_region_mask = np.ones((h+2,w+2), np.uint8)\n",
    "    high_region_mask[1:h+1,1:w+1] = depthImage < 0.04 # > 0.04 False == 0, Flood fill will fill pixels with 0\n",
    "    resultImg = np.zeros((h,w), np.uint8)\n",
    "    \n",
    "    #define plane edge\n",
    "    plane_edge = 25\n",
    "    \n",
    "    x1 = plane_edge\n",
    "    x2 = w - plane_edge\n",
    "    y1 = plane_edge\n",
    "    y2 = h - plane_edge\n",
    "    \n",
    "    high_list = []\n",
    "    \n",
    "    for y in range(plane_edge, y2):\n",
    "        if high_region_mask[y+1,x1+1] == 0 and resultImg[y,x1] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x1, y),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x1,y))\n",
    "            \n",
    "        if high_region_mask[y+1,x2+1] == 0 and resultImg[y,x2] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x2, y),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x2,y))\n",
    "            \n",
    "    for x in range(plane_edge, x2):\n",
    "        if high_region_mask[y1+1,x+1] == 0 and resultImg[y1,x] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x, y1),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x, y1))\n",
    "            \n",
    "        if high_region_mask[y2+1,x+1] == 0 and resultImg[y2,x] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x, y2),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x, y2))\n",
    "    \n",
    "    return resultImg, high_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Hand_mask(Edge_map, high_list, High_region_Image):\n",
    "    \"\"\"\n",
    "    Flood fill from high region position and stop when reach edge\n",
    "    Only fill in the hight region mask \n",
    "    ==> Prevent flood fill from seed which filled region does not the hight region\n",
    "    \"\"\"\n",
    "    h, w = Edge_map.shape[:2]\n",
    "    \n",
    "    resultImg = Edge_map.copy()\n",
    "    resultImg.dtype = 'uint8'\n",
    "    mask = np.zeros((h+2,w+2), np.uint8)\n",
    "    mask1 = np.ones((h+2,w+2), np.uint8)\n",
    "    mask1[1:h+1,1:w+1] = High_region_Image == False\n",
    "\n",
    "    for i in range(len(high_list)):\n",
    "        cv2.floodFill(resultImg, mask1, high_list[i],True,cv2.FLOODFILL_FIXED_RANGE)\n",
    "    \n",
    "    resultImg = resultImg - Edge_map\n",
    "    \n",
    "    return resultImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Fingertip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fingertip(hand_mask):\n",
    "    '''\n",
    "        return: \n",
    "        @cnt: contours\n",
    "    '''\n",
    "    fingertips = []\n",
    "    low_threshold = 0\n",
    "    high_threshold = 1\n",
    "    kernel_size = 3\n",
    "    \n",
    "    #Smooth the mask and find the contours\n",
    "    smooth_mask = cv2.GaussianBlur(hand_mask,(kernel_size, kernel_size), 0)\n",
    "    (_, cnts, _) = cv2.findContours(smooth_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #convert the result image into RGB image\n",
    "    contours_image = cv2.convertScaleAbs(smooth_mask, alpha=(255))\n",
    "    contours_image = cv2.cvtColor(contours_image, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Find the contour with max area\n",
    "    maxArea = 0\n",
    "    for i in range(len(cnts)):\n",
    "        area = cv2.contourArea(cnts[i])\n",
    "        if area > maxArea:\n",
    "            maxArea = area\n",
    "            hull = cv2.convexHull(cnts[i])\n",
    "            Contours = cnts[i]\n",
    "    \n",
    "    cx, cy = (0,0)\n",
    "    if len(cnts) > 0 : \n",
    "        # get centroid from hand, then Draw the center and Hull_Convex\n",
    "        M = cv2.moments(hull)\n",
    "        cx = int(M[\"m10\"]/M[\"m00\"])\n",
    "        cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "        cv2.circle(contours_image, (cx, cy), 5, (0,0,255), -1)\n",
    "        cv2.drawContours(contours_image, [hull], -1, (255,0,0), 2)\n",
    "        \n",
    "        #Find the Fingertips\n",
    "        skip = 3\n",
    "        Convex = (0,0)\n",
    "        threshold = 3\n",
    "        for i in range(skip, len(Contours)-skip):\n",
    "            p = Contours[i-skip]\n",
    "            q = Contours[i]\n",
    "            r = Contours[i+skip]\n",
    "            \n",
    "            dot = np.dot(q-p,(r-p).T)\n",
    "            if abs(dot) < 20:\n",
    "                points = (p[0,0],p[0,1])\n",
    "                IsnotEdge = points[0]!=0 and points[1]!=0 and points[0]!=contours_image.shape[1] and points[1]!=contours_image.shape[0]\n",
    "                IsConvex, hull = Points_is_convex(hull, points, threshold)\n",
    "                Labeled = (Convex[0] - points[0]) <= threshold and abs(Convex[1] - points[1]) <= threshold\n",
    "                #if the point is in the convex list and haven't be labeled, then add it to Fingertip list\n",
    "                if IsConvex and not Labeled and IsnotEdge:\n",
    "                    Convex = points\n",
    "                    fingertips.append(Convex)\n",
    "                    cv2.circle(contours_image, Convex, 5 , (0,255,0) ,-1)\n",
    "                    \n",
    "    print(len(fingertips))\n",
    "    return cnts, contours_image, (cx, cy), np.asarray(fingertips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cotour Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Points_is_convex(hull, points, threshold):\n",
    "    label = False\n",
    "    label_hull = hull.copy()\n",
    "    for i in range(len(hull)):\n",
    "        if abs(hull[i,0,0] - points[0]) <= threshold and abs(hull[i,0,1] - points[1]) <= threshold:\n",
    "            label_hull[i,0] = (-1, -1)\n",
    "            label = True\n",
    "    return label, label_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_open_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##True: white 1  False: black 0\n",
    "# ptset = np.array(([False, False, False],\n",
    "#             [True, True, False],\n",
    "#             [False, True, False]))\n",
    "# plt.imshow(ptset,plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands_center = np.zeros((2, 2))\n",
    "fingertips = np.zeros((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_distance(x, y):\n",
    "    return np.power(np.power(x[0]-y[0], 2) + np.power(x[1] - y[1], 2), 0.5)\n",
    "   \n",
    "def get_tracking_index(tracking_array, new_tracking_positions, euclidean_distance = 0.1):\n",
    "    '''\n",
    "        return:\n",
    "        found_index[x, 0] = index\n",
    "        found_index[x, 1] = distance\n",
    "    '''\n",
    "    \n",
    "    tracking_size, _ = tracking_array.shape\n",
    "    new_position_size, _= new_tracking_positions.shape\n",
    "    print('new position size: ', new_position_size, _)\n",
    "    found_indexs = np.zeros((new_position_size, 2))\n",
    "    \n",
    "    for j in range(1, new_position_size):\n",
    "        index = -1\n",
    "        distance = -1\n",
    "        for i in range(1, tracking_size):\n",
    "            distance = get_euclidean_distance(tracking_array[i], new_tracking_positions[j])\n",
    "            if(distance < euclidean_distance):\n",
    "                index = i\n",
    "                # track the closet point\n",
    "                euclidean_distance = distance\n",
    "        found_indexs[j, 0] = index\n",
    "        found_indexs[j, 1] = distance\n",
    "        \n",
    "    # remove no udpate position\n",
    "    for i, h in enumerate(tracking_array):\n",
    "        need_udate = False\n",
    "        for j, index in enumerate(found_indexs):\n",
    "            if(found_indexs[j, 0] == i):\n",
    "                need_udate = True\n",
    "                # update new postion\n",
    "                tracking_array[i] = new_tracking_positions[j]\n",
    "                break\n",
    "        if(need_udate == False):\n",
    "            # remove no udate infroamtion\n",
    "            tracking_array[i] = (-1, -1)\n",
    "        \n",
    "    return tracking_array\n",
    "\n",
    "def hand_tracking(new_center, new_tips):\n",
    "    '''\n",
    "        by Yuan-Syun Ye\n",
    "    '''\n",
    "    global hands_center, fingertips\n",
    "    \n",
    "    new_center = np.array([[new_center[0], new_center[1]]])\n",
    "    \n",
    "    print('-------------Hand Tracking---------------')\n",
    "    print('centers: ', new_center)\n",
    "    print('new tips: ', new_tips)\n",
    "    \n",
    "    # using Euclidean distance to tracking each postion.\n",
    "    hands_center = get_tracking_index(hands_center, new_center)\n",
    "    fingertips = get_tracking_index(fingertips, new_tips)\n",
    "    \n",
    "    print('hand center: ', hands_center)\n",
    "    print('fingertips: ', fingertips)\n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Touching Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: 123.rrf\n",
      "====================================\n",
      "        Camera information\n",
      "====================================\n",
      "Type:            PICOFLEXX\n",
      "Width:           224\n",
      "Height:          171\n",
      "Operation modes: 1\n",
      "    MODE_PLAYBACK\n",
      "        this operation mode has 1009844480 streams\n",
      "CameraInfo items: 0\n",
      "isConnected True\n",
      "getFrameRate 0\n",
      "200\n",
      "Inliner Number\n",
      " 34235\n",
      "Inliner plane\n",
      " [ 0.00022304 -0.00331474 -0.01566024  0.00376741]\n",
      "3\n",
      "-------------Hand Tracking---------------\n",
      "centers:  [[100  84]]\n",
      "new tips:  [[173 164]\n",
      " [192 130]\n",
      " [178  62]]\n",
      "new position size:  1 2\n",
      "new position size:  3 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\winpython\\python-3.6.5.amd64\\lib\\site-packages\\numpy\\linalg\\linalg.py:2160: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  (ord in ('f', 'fro') and ndim == 2) or\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-3e170d05fe4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-3e170d05fe4d>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mprocess_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgray_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints3D_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfidenceIndex_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfidence_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpainter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseconds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-c711a5e36af7>\u001b[0m in \u001b[0;36mprocess_event\u001b[1;34m(z_queue, gray_queue, points3D_queue, ConfidenceIndex_queue, Confidence_queue, painter, seconds)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mcnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontours_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhand_center\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfingertips\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_fingertip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHand_mask_Image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;31m# tracking user hand and fingertips\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0mhand_tracking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhand_center\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfingertips\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-80cf950567fa>\u001b[0m in \u001b[0;36mhand_tracking\u001b[1;34m(new_center, new_tips)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m# using Euclidean distance to tracking each postion.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mhands_center\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tracking_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhands_center\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_center\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mfingertips\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tracking_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfingertips\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_tips\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hand center: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhands_center\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-80cf950567fa>\u001b[0m in \u001b[0;36mget_tracking_index\u001b[1;34m(tracking_array, new_tracking_positions, euclidean_distance)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mdistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtracking_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mdistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtracking_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_tracking_positions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\software\\winpython\\python-3.6.5.amd64\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2159\u001b[0m         if ((ord is None) or\n\u001b[0;32m   2160\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mord\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'f'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fro'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2161\u001b[1;33m             (ord == 2 and ndim == 1)):\n\u001b[0m\u001b[0;32m   2162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2163\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'K'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "def main ():\n",
    "    parser = argparse.ArgumentParser(usage=__doc__)\n",
    "    add_camera_opener_options(parser)\n",
    "    parser.add_argument(\"--seconds\", type=int, default=15, help=\"duration to capture data\")\n",
    "    options = parser.parse_args(args=['--rrf','123.rrf','--seconds', '5'])\n",
    "    opener = CameraOpener(options)\n",
    "    cam = opener.open_camera()\n",
    "\n",
    "    print_camera_info (cam)\n",
    "    print(\"isConnected\", cam.isConnected())\n",
    "    print(\"getFrameRate\", cam.getFrameRate())\n",
    "    print(cam.getFilterLevel())\n",
    "\n",
    "    z_queue = queue.Queue()\n",
    "    gray_queue = queue.Queue()\n",
    "    points3D_queue = queue.Queue()\n",
    "    ConfidenceIndex_queue = queue.Queue()\n",
    "    Confidence_queue = queue.Queue()\n",
    "    l = MyListener(z_queue,gray_queue,points3D_queue,ConfidenceIndex_queue,Confidence_queue)\n",
    "\n",
    "    cam.registerDataListener(l)\n",
    "    cam.startCapture()\n",
    "\n",
    "    process_event(z_queue, gray_queue, points3D_queue, ConfidenceIndex_queue, Confidence_queue, painter=l, seconds=5)\n",
    "\n",
    "    cam.stopCapture()\n",
    "    \n",
    "    \n",
    "if (__name__ == \"__main__\"):\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#show plane edge\n",
    "test = np.zeros((171,224), np.uint8)\n",
    "l = 30\n",
    "test[l:171-l,l:224-l] = 1\n",
    "plt.imshow(test),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "(5, 6)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'tuple' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-cc11930896c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'tuple' and 'tuple'"
     ]
    }
   ],
   "source": [
    "x= [(1,2), (3, 4)]\n",
    "y = [(5,6), (7,8)]\n",
    "print(x[0])\n",
    "print(y[0])\n",
    "d = np.linalg.norm(x[0]-y[0])\n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

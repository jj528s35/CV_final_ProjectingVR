{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import roypy\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time\n",
    "import queue\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "from PIL import Image, ImageDraw\n",
    "from sample_camera_info import print_camera_info\n",
    "from roypy_sample_utils import CameraOpener, add_camera_opener_options\n",
    "\n",
    "# 調整np.array輸出格式\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener(roypy.IDepthDataListener):\n",
    "\n",
    "    def __init__(self, z_queue, gray_queue, points3D_queue, ConfidenceIndex_queue, Confidence_queue, undistortImage=False):\n",
    "        super(MyListener, self).__init__()\n",
    "        self.z_queue = z_queue\n",
    "        self.gray_queue = gray_queue\n",
    "        self.points3D_queue = points3D_queue\n",
    "        self.ConfidenceIndex_queue = ConfidenceIndex_queue\n",
    "        self.Confidence_queue = Confidence_queue\n",
    "        self.undistortImage = undistortImage\n",
    "        self.cameraMatrix = None\n",
    "        self.distortionCoefficients = None\n",
    "\n",
    "    def onNewData(self, data):\n",
    "        zvalues = []\n",
    "        xvalues = []\n",
    "        yvalues = []\n",
    "        grayvalues = []\n",
    "        points3D = []\n",
    "        ConfidenceIndexvalues = [] # whether the pixel measured a valid 3D value\n",
    "        Confidencevalue = []\n",
    "        for i in range(data.getNumPoints()):\n",
    "            zvalues.append(data.getZ(i))\n",
    "            xvalues.append(data.getX(i))\n",
    "            yvalues.append(data.getY(i))\n",
    "            grayvalues.append(data.getGrayValue(i))\n",
    "            \n",
    "            Confidencevalue.append(data.getDepthConfidence(i))\n",
    "            if data.getDepthConfidence(i) > 0:\n",
    "                ConfidenceIndexvalues.append(i)\n",
    "            \n",
    "        zarray = np.asarray(zvalues)\n",
    "        z = zarray.reshape (-1, data.width)        \n",
    "        self.z_queue.put(z)\n",
    "        \n",
    "        xarray = np.asarray(xvalues)\n",
    "        x = xarray.reshape (-1, data.width)\n",
    "        \n",
    "        yarray = np.asarray(yvalues)\n",
    "        y = yarray.reshape (-1, data.width)\n",
    "        \n",
    "        points3D = np.dstack((x,y,z))\n",
    "        self.points3D_queue.put(points3D)\n",
    "        \n",
    "        \n",
    "        grayarray = np.asarray(grayvalues)\n",
    "        q = grayarray.reshape (-1, data.width)        \n",
    "        self.gray_queue.put(q)\n",
    "        \n",
    "        Confidencearray = np.asarray(Confidencevalue)\n",
    "        Confidence = Confidencearray.reshape (-1, data.width)\n",
    "        self.Confidence_queue.put(Confidence)\n",
    "        #ConfidenceIndex_queue\n",
    "        ConfidenceIndex = np.asarray(ConfidenceIndexvalues)\n",
    "        self.ConfidenceIndex_queue.put(ConfidenceIndex)\n",
    "\n",
    "    def paint(self, data, name, isGray = False, cv2_show = False):\n",
    "        \"\"\"\n",
    "        Called in the main thread, with data containing one of the items that was added to the queue in onNewData\n",
    "        :param data:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if cv2_show == True: \n",
    "            cv2.imshow(name, data)\n",
    "        else:\n",
    "            # create a figure and show the raw data\n",
    "            plt.figure(1)\n",
    "            if isGray == False:\n",
    "                plt.imshow(data),plt.title(name),plt.axis('off')\n",
    "            else: \n",
    "                plt.imshow(data,plt.cm.gray),plt.title(name),plt.axis('off')\n",
    "\n",
    "            plt.show(block=False)\n",
    "            plt.draw()\n",
    "\n",
    "            # this pause is needed to ensure the drawing for some backends\n",
    "            plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracker Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_event(z_queue, gray_queue, points3D_queue, ConfidenceIndex_queue, Confidence_queue, painter=None, seconds=150):\n",
    "    First = True\n",
    "    # create a loop that will run for the given amount of time\n",
    "    t_end = time.time() + seconds\n",
    "    while time.time() < t_end:\n",
    "        \n",
    "        # Press Q on keyboard to exit \n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            # try to retrieve an item from the queue\n",
    "            # this will block until an item can be retrieved\n",
    "            # or the timeout of 1 second is hit\n",
    "\n",
    "            zImage = z_queue.get(True) if z_queue else None\n",
    "            grayImage_int32 = gray_queue.get(True) if gray_queue else None\n",
    "            points3D = points3D_queue.get(True) if points3D_queue else None\n",
    "            ConfidenceIndex = ConfidenceIndex_queue.get(True) if ConfidenceIndex_queue else None\n",
    "            Confidence = Confidence_queue.get(True) if Confidence_queue else None\n",
    "        except queue.Empty:\n",
    "            # this will be thrown when the timeout is hit\n",
    "            break\n",
    "            # break\n",
    "        else:\n",
    "            \n",
    "            size = points3D.shape\n",
    "            cv2.imshow('zImage', zImage)\n",
    "            \n",
    "            if First == True:\n",
    "                #RANSAM to get surface plane\n",
    "                surface_plane, depthImg, plane_mask = RANSAM(points3D, ConfidenceIndex, ransac_iteration = 500, inliner_threshold = 0.01)\n",
    "                First = False\n",
    "                print(\"firstly RANSAM\")\n",
    "            else:\n",
    "                #\n",
    "                depthImg = get_depth_map(points3D, surface_plane)\n",
    "                #Canny edge map(infrared image) + threshold based edge map(depth image)\n",
    "                Cannyedges, Threshold_based_edge, Edge_map, grayImage = get_edge_map(grayImage_int32, depthImg)\n",
    "                #Get hight region by Hight and record its position\n",
    "                High_region_Image, high_region_list = get_high_region(depthImg)\n",
    "                #Get Hand mask by Flood fill from high region position with Edge map\n",
    "                Hand_mask_Image = get_Hand_mask(Edge_map, high_region_list, High_region_Image)\n",
    "                #\n",
    "                cnt, contours_image, hand_center, fingertips = find_fingertip(Hand_mask_Image)\n",
    "                # tracking user hand and fingertips\n",
    "                hands_hand, fingertips_pos, tracking_iamge = hand_tracking(hand_center, fingertips, points3D, contours_image)\n",
    "                # detecte fingers whenther touching the surface\n",
    "                touched_flag, touching_detection_image = touching_detection(fingertips, Hand_mask_Image, depthImg, contours_image)\n",
    "                \n",
    "                #Show original image and result image\n",
    "#                 painter.paint(grayImage_int32,'Gray Image',True)\n",
    "#                 painter.paint(depthImg,'Depth')\n",
    "#                 painter.paint(Cannyedges,'Canny Edges',True)\n",
    "#                 painter.paint(Threshold_based_edge,'Threshold_based Edge',True)\n",
    "#                 painter.paint(Edge_map,'Edge map',True)\n",
    "#                 painter.paint(High_region_Image,'High region Image',True)\n",
    "#                 painter.paint(Hand_mask_Image,'Hand mask Image')\n",
    "#                 painter.paint(contours_image,'Contours Image',True)\n",
    "                painter.paint(tracking_iamge,'tracking Image',False, True)\n",
    "                painter.paint(touching_detection_image,'touched Image', False, True)\n",
    "            \n",
    "#             #Store Image\n",
    "#             IsStore = False\n",
    "#             if IsStore == True:\n",
    "#                 matplotlib.image.imsave('zImage.png', zImage)\n",
    "#                 matplotlib.image.imsave('grayImage_int32.png', grayImage_int32)\n",
    "#                 matplotlib.image.imsave('points3D.png', points3D)\n",
    "#                 matplotlib.image.imsave('Confidence.png', Confidence)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANSAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dis_pt2plane(pts, a, b, c, d):\n",
    "    \"\"\"\n",
    "    Compute the distance from points to the plane\n",
    "    \"\"\"\n",
    "    normal = math.sqrt(a*a+b*b+c*c)\n",
    "    if normal == 0:\n",
    "        normal = 1\n",
    "    \n",
    "    v = np.array([a,b,c])\n",
    "    dis = abs(np.dot(pts,v.T)+d)/normal\n",
    "    return dis\n",
    "\n",
    "def get_Plane(sampts):\n",
    "    \"\"\"\n",
    "    Compute the equation of the plane\n",
    "    \"\"\"\n",
    "    p1 = sampts[0]\n",
    "    p2 = sampts[1]\n",
    "    p3 = sampts[2]\n",
    "    \n",
    "    a = ( (p2[1]-p1[1])*(p3[2]-p1[2])-(p2[2]-p1[2])*(p3[1]-p1[1]) )\n",
    "    b = ( (p2[2]-p1[2])*(p3[0]-p1[0])-(p2[0]-p1[0])*(p3[2]-p1[2]) )\n",
    "    c = ( (p2[0]-p1[0])*(p3[1]-p1[1])-(p2[1]-p1[1])*(p3[0]-p1[0]) )\n",
    "    d = ( 0-(a*p1[0]+b*p1[1]+c*p1[2]) )\n",
    "    \n",
    "    return a,b,c,d\n",
    "\n",
    "def Random3points(points3D, ConfidenceIndex):\n",
    "    \"\"\"\n",
    "    Random choose 3 Confidence points\n",
    "    \"\"\"\n",
    "    sample_number = 3\n",
    "    sample_point_index = random.sample(range(ConfidenceIndex.shape[0]), sample_number)\n",
    "    sample_points = np.zeros((sample_number,3))\n",
    "    for i in range(sample_number):\n",
    "        Confidence_point_index = sample_point_index[i]\n",
    "        index = ConfidenceIndex[Confidence_point_index]\n",
    "        y = index // points3D.shape[1]\n",
    "        x = index % points3D.shape[1]\n",
    "        sample_points[i] = points3D[y][x]\n",
    "    return sample_points\n",
    "\n",
    "# def Random3points(points3D):\n",
    "#     sample_number = 3\n",
    "#     sample_point_index = random.sample(range(points3D.shape[0]*points3D.shape[1]), sample_number)\n",
    "#     sample_points = np.zeros((sample_number,3))\n",
    "#     for i in range(sample_number):\n",
    "#         index = sample_point_index[i]\n",
    "#         y = index // points3D.shape[1]\n",
    "#         x = index % points3D.shape[1]\n",
    "#         sample_points[i] = points3D[y][x]\n",
    "#     return sample_points\n",
    "\n",
    "def get_inliner_num(points3D,a,b,c,d,inliner_threshold):\n",
    "    \"\"\"\n",
    "    Compute the liner points which distance to plane < threshold\n",
    "    Also get distance from points to the plane (new Depth Image which re-project depth pixels in surface plane)\n",
    "    \"\"\"\n",
    "    inliner_num = 0\n",
    "    \n",
    "    dist = Dis_pt2plane(points3D,a,b,c,d)\n",
    "    inliner_mask = dist < inliner_threshold\n",
    "    inliner_num = np.sum(inliner_mask)\n",
    "    return inliner_num, inliner_mask, dist\n",
    "\n",
    "def RANSAM(points3D, ConfidenceIndex, ransac_iteration = 1000, inliner_threshold = 0.01):\n",
    "    best_inlinernum = -1\n",
    "    best_inlinernum = 0\n",
    "    best_plane = np.zeros((1,4))\n",
    "    best_depthImage = np.zeros((points3D.shape[0],points3D.shape[1]))\n",
    "    best_plane_mask = np.zeros((points3D.shape[0],points3D.shape[1]))\n",
    "#     best_sampts = np.zeros((3,3))\n",
    "    \n",
    "#     print(points3D.shape,points3D[80:90,110])\n",
    "    for i in range(ransac_iteration):\n",
    "        sampts = Random3points(points3D, ConfidenceIndex)\n",
    "        a,b,c,d = get_Plane(sampts)\n",
    "        \n",
    "        inliner_num, inliner_mask, depthImage = get_inliner_num(points3D,a,b,c,d,inliner_threshold)\n",
    "        if(inliner_num > best_inlinernum):\n",
    "            best_inlinernum = inliner_num\n",
    "            best_plane = np.array([a,b,c,d])\n",
    "            best_plane_mask = inliner_mask\n",
    "            best_depthImage = depthImage\n",
    "#             best_sampts = sampts\n",
    "            \n",
    "    print(\"Inliner Number\\n\", best_inlinernum)\n",
    "    print(\"Inliner plane\\n\", best_plane)\n",
    "    return best_plane, best_depthImage, best_plane_mask\n",
    "\n",
    "# ptset = np.array(([0, 0, 0],\n",
    "#             [1, 2, 0],\n",
    "#             [2, 2, 0]))\n",
    "# a,b,c,d = get_Plane(ptset)\n",
    "# pts = np.zeros((2,2,3))\n",
    "# pts[0,0] = np.array([0, 0, 1])\n",
    "# pts[0,1] = np.array([0, 0, 2])\n",
    "# pts[1,0] = np.array([0, 0, 3])\n",
    "# pts[1,1] = np.array([0, 0, 4])\n",
    "# z = Dis_pt2plane(pts,a,b,c,d)\n",
    "# print(z,z.shape)\n",
    "# get_inliner_num(pts,a,b,c,d,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_map(points3D,plane):\n",
    "    \"\"\"\n",
    "    Compute the liner points which distance to plane < threshold\n",
    "    Also get distance from points to the plane (new Depth Image which re-project depth pixels in surface plane)\n",
    "    \"\"\"\n",
    "    dist = Dis_pt2plane(points3D,plane[0],plane[1],plane[2],plane[3])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_map(grayImage,depthImage):\n",
    "    \"\"\"\n",
    "    Canny Edge map\n",
    "    turn grayImg from int32 to int8\n",
    "    blur the grayImg then do Canny Edge\n",
    "    \"\"\"\n",
    "    low_threshold = 1\n",
    "    high_threshold = 8\n",
    "    grayimg_int8 = cv2.convertScaleAbs(grayImage, alpha=(255.0/65535.0))\n",
    "    \n",
    "    kernel_size = 3\n",
    "    blur_gray = cv2.GaussianBlur(grayimg_int8,(kernel_size, kernel_size), 0)\n",
    "    Cannyedges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "    \n",
    "    \"\"\"\n",
    "    Threshold based Edge map\n",
    "    if depth between the pixel and its nearby pixels > near_depth_threshold, then labeled it\n",
    "    \"\"\"\n",
    "    near_depth_threshold = 0.05\n",
    "#     print(\"sum\",np.sum(depthImage > near_depth_threshold))\n",
    "    Threshold_based_edge = np.zeros((depthImage.shape[0],depthImage.shape[1]))\n",
    "    for y in range(1,depthImage.shape[0]-1):\n",
    "        for x in range(1,depthImage.shape[1]-1):\n",
    "            near1 = abs(depthImage[y,x] - depthImage[y-1,x-1]) > near_depth_threshold\n",
    "            near2 = abs(depthImage[y,x] - depthImage[y-1,x]) > near_depth_threshold\n",
    "            near3 = abs(depthImage[y,x] - depthImage[y-1,x+1]) > near_depth_threshold\n",
    "            near4 = abs(depthImage[y,x] - depthImage[y,x-1]) > near_depth_threshold\n",
    "            near5 = abs(depthImage[y,x] - depthImage[y,x+1]) > near_depth_threshold\n",
    "            near6 = abs(depthImage[y,x] - depthImage[y+1,x-1]) > near_depth_threshold\n",
    "            near7 = abs(depthImage[y,x] - depthImage[y+1,x]) > near_depth_threshold\n",
    "            near8 = abs(depthImage[y,x] - depthImage[y+1,x+1]) > near_depth_threshold\n",
    "            \n",
    "            labeled_it = near1 or near2 or near3 or near4 or near5 or near6 or near7 or near8\n",
    "            Threshold_based_edge[y,x] = labeled_it\n",
    "    \"\"\"\n",
    "    Merge Canny Edge map and Threshold based Edge map\n",
    "    \"\"\"\n",
    "#     Edge_map = np.logical_and(Cannyedges,Threshold_based_edge)\n",
    "    Edge_map = np.logical_or(Cannyedges,Threshold_based_edge)\n",
    "    \n",
    "    return Cannyedges,Threshold_based_edge, Edge_map, blur_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find High Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_region(depthImage):\n",
    "    \"\"\"\n",
    "    Define plane edge\n",
    "    High region : > 0.04 \n",
    "    ==> Flood fill mask : if pixels value > 0.04, then its value of mask image = 0 \n",
    "    ==> mask = depthImage < 0.04\n",
    "    \n",
    "    Next, reject the region which dose not connet with plane edge and record its position\n",
    "    ==>Just do Flood fill around the plane edge\n",
    "    \"\"\"\n",
    "    h, w = depthImage.shape[:2]\n",
    "    high_region_mask = np.ones((h+2,w+2), np.uint8)\n",
    "    high_region_mask[1:h+1,1:w+1] = depthImage < 0.04 # > 0.04 False == 0, Flood fill will fill pixels with 0\n",
    "    resultImg = np.zeros((h,w), np.uint8)\n",
    "    \n",
    "    #define plane edge\n",
    "    plane_edge = 25\n",
    "    \n",
    "    x1 = plane_edge\n",
    "    x2 = w - plane_edge\n",
    "    y1 = plane_edge\n",
    "    y2 = h - plane_edge\n",
    "    \n",
    "    high_list = []\n",
    "    \n",
    "    for y in range(plane_edge, y2):\n",
    "        if high_region_mask[y+1,x1+1] == 0 and resultImg[y,x1] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x1, y),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x1,y))\n",
    "            \n",
    "        if high_region_mask[y+1,x2+1] == 0 and resultImg[y,x2] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x2, y),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x2,y))\n",
    "            \n",
    "    for x in range(plane_edge, x2):\n",
    "        if high_region_mask[y1+1,x+1] == 0 and resultImg[y1,x] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x, y1),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x, y1))\n",
    "            \n",
    "        if high_region_mask[y2+1,x+1] == 0 and resultImg[y2,x] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x, y2),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x, y2))\n",
    "    \n",
    "    return resultImg, high_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Hand_mask(Edge_map, high_list, High_region_Image):\n",
    "    \"\"\"\n",
    "    Flood fill from high region position and stop when reach edge\n",
    "    Only fill in the hight region mask \n",
    "    ==> Prevent flood fill from seed which filled region does not the hight region\n",
    "    \"\"\"\n",
    "    h, w = Edge_map.shape[:2]\n",
    "    \n",
    "    resultImg = Edge_map.copy()\n",
    "    resultImg.dtype = 'uint8'\n",
    "    mask = np.zeros((h+2,w+2), np.uint8)\n",
    "    mask1 = np.ones((h+2,w+2), np.uint8)\n",
    "    mask1[1:h+1,1:w+1] = High_region_Image == False\n",
    "\n",
    "    for i in range(len(high_list)):\n",
    "        cv2.floodFill(resultImg, mask1, high_list[i],True,cv2.FLOODFILL_FIXED_RANGE)\n",
    "    \n",
    "    resultImg = resultImg - Edge_map\n",
    "    \n",
    "    return resultImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Fingertip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fingertip(hand_mask, debug = False):\n",
    "    '''\n",
    "        return: \n",
    "        @cnt: contours\n",
    "    '''\n",
    "    fingertips = []\n",
    "    low_threshold = 0\n",
    "    high_threshold = 1\n",
    "    kernel_size = 7\n",
    "    \n",
    "    #Smooth the mask and find the contours\n",
    "    smooth_mask = cv2.GaussianBlur(hand_mask,(kernel_size, kernel_size), 0)\n",
    "    (_, cnts, _) = cv2.findContours(smooth_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #convert the result image into RGB image\n",
    "    contours_image = cv2.convertScaleAbs(smooth_mask, alpha=(255))\n",
    "    contours_image = cv2.cvtColor(contours_image, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Find the contour with max area\n",
    "    maxArea = 0\n",
    "    hull = None\n",
    "    for i in range(len(cnts)):\n",
    "        area = cv2.contourArea(cnts[i])\n",
    "        if area > maxArea:\n",
    "            maxArea = area\n",
    "            hull = cv2.convexHull(cnts[i])\n",
    "            Contours = cnts[i]\n",
    "    \n",
    "    cx, cy = (0,0)\n",
    "    if hull is not None : \n",
    "        # get centroid from hand, then Draw the center and Hull_Convex\n",
    "        M = cv2.moments(hull)\n",
    "        cx = int(M[\"m10\"]/M[\"m00\"])\n",
    "        cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "        if(debug == True):\n",
    "            cv2.circle(contours_image, (cx, cy), 5, (0,0,255), 3)\n",
    "        cv2.drawContours(contours_image, [Contours], -1, (255,0,0), 2)\n",
    "        \n",
    "        #Find the Fingertips\n",
    "        fingertips, contours_image = find_fingertips_by_dot(Contours, hull, contours_image)\n",
    "        \n",
    "        \n",
    "    print('fingertips count:', len(fingertips))\n",
    "    return cnts, contours_image, (cx, cy), np.asarray(fingertips)\n",
    "\n",
    "\n",
    "def find_fingertips_by_dot(Contours, hull, contours_image, debug=False):\n",
    "    fingertips = []\n",
    "    skip = 2\n",
    "    Convex = (0,0)\n",
    "    threshold = 10\n",
    "    first = True\n",
    "    for i in range(skip, len(Contours)-skip):\n",
    "        p = Contours[i-skip]\n",
    "        q = Contours[i]\n",
    "        r = Contours[i+skip]\n",
    "\n",
    "        dot = np.dot(q-p,(r-p).T)\n",
    "        if abs(dot) < 20:\n",
    "            points = (p[0,0],p[0,1])\n",
    "            if first == True:\n",
    "                Convex = points\n",
    "                first = False\n",
    "            IsnotEdge = points[0]!=0 and points[1]!=0 and points[0]!=contours_image.shape[1] and points[1]!=contours_image.shape[0]\n",
    "            IsConvex = Points_is_convex(hull, points, threshold)\n",
    "            Labeled = abs(Convex[0] - points[0]) > threshold and abs(Convex[1] - points[1]) > threshold\n",
    "            #if the point is in the convex list and haven't be labeled, then add it to Fingertip list\n",
    "            if IsConvex and Labeled and IsnotEdge:\n",
    "                Convex = points\n",
    "                fingertips.append(Convex)\n",
    "                if(debug==True):\n",
    "                    cv2.circle(contours_image, Convex, 5 , (0,255,0) , 3)\n",
    "    return fingertips, contours_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cotour Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Points_is_convex_all(hull, points, threshold):\n",
    "    label = False\n",
    "    label_hull = hull.copy()\n",
    "    for i in range(len(hull)):\n",
    "        if abs(hull[i,0,0] - points[0]) <= threshold and abs(hull[i,0,1] - points[1]) <= threshold:\n",
    "            label_hull[i,0] = (-1, -1)\n",
    "            label = True\n",
    "    return label, label_hull\n",
    "\n",
    "def Points_is_convex(hull, points, threshold):\n",
    "    label = False\n",
    "    label_hull = hull.copy()\n",
    "    for i in range(len(hull)):\n",
    "        if abs(hull[i,0,0] - points[0]) <= threshold and abs(hull[i,0,1] - points[1]) <= threshold:\n",
    "            label_hull[i,0] = (-1, -1)\n",
    "            label = True\n",
    "            return label\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_open_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##True: white 1  False: black 0\n",
    "# ptset = np.array(([False, False, False],\n",
    "#             [True, True, False],\n",
    "#             [False, True, False]))\n",
    "# plt.imshow(ptset,plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands_center = np.zeros((2, 2))\n",
    "fingertips = np.zeros((10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_euclidean_distance(x, y, threed_points):\n",
    "    a = threed_points[int(x[1]), int(x[0])]\n",
    "    b = threed_points[int(y[1]), int(y[0])]\n",
    "    return np.power((np.power(a[0] - b[0], 2) + np.power(a[1] - b[1], 2) + np.power(a[2] - b[2], 2)), 0.5)\n",
    "   \n",
    "def get_tracking_index(tracking_array, new_tracking_positions, threed_points, euclidean_distance = 0.1):\n",
    "    '''\n",
    "        return:\n",
    "        found_index[x, 0] = index\n",
    "        found_index[x, 1] = distance\n",
    "    '''\n",
    "    tracking_size, _ = tracking_array.shape\n",
    "    if(len(new_tracking_positions)>0):\n",
    "        new_position_size, _= new_tracking_positions.shape\n",
    "        pairs = np.zeros((new_position_size, 2))\n",
    "    else:\n",
    "        new_position_size = 0\n",
    "        pairs = []\n",
    "        \n",
    "    # track the closet point\n",
    "    for j in range(1, new_position_size):\n",
    "        index = -1\n",
    "        distance = -1\n",
    "        min_distance = euclidean_distance\n",
    "        for i in range(1, tracking_size):\n",
    "            # skip no information\n",
    "            if((tracking_array[i][0] == -1) and (tracking_array[i][1]==-1)):\n",
    "                continue\n",
    "            distance = get_euclidean_distance(tracking_array[i], new_tracking_positions[j], threed_points)\n",
    "            if(distance < min_distance):\n",
    "                index = i\n",
    "                min_distance = distance\n",
    "        pairs[j][0] = index\n",
    "        pairs[j][1] = min_distance\n",
    "#     print('pairs: ', pairs)\n",
    "        \n",
    "    # remove no udpate position\n",
    "    for i, h in enumerate(tracking_array):\n",
    "        need_udate = False\n",
    "        for j, p in enumerate(pairs):\n",
    "            if(pairs[j, 0] == i):\n",
    "                need_udate = True\n",
    "                # update new postion\n",
    "                tracking_array[i] = new_tracking_positions[j]\n",
    "                break\n",
    "        if(need_udate == False):\n",
    "            # remove no udate position\n",
    "            tracking_array[i] = [-1, -1]\n",
    "    \n",
    "    # insert new position\n",
    "    for i, p in enumerate(pairs):\n",
    "        if(pairs[i][0] == -1):\n",
    "            for j, item in enumerate(tracking_array):\n",
    "                if((tracking_array[j][0] == -1) and (tracking_array[j][1] == -1)):\n",
    "                    tracking_array[j] = new_tracking_positions[i]\n",
    "                    break\n",
    "        \n",
    "    return tracking_array\n",
    "\n",
    "def hand_tracking(new_center, new_tips, threed_points, draw_image=None):\n",
    "    '''\n",
    "        by Yuan-Syun Ye\n",
    "        \n",
    "        Hand from the current frame are matched to hands in the previous frame by Euclidean distance with a fixed upper limit\n",
    "        on movement (i.e., assuming hands do not move more than 10 cm in a single, or 2.50 m/s).\n",
    "    '''\n",
    "    global hands_center, fingertips\n",
    "    \n",
    "    new_center = np.array([[new_center[0], new_center[1]]])\n",
    "    \n",
    "#     print('-------------Hand Tracking---------------')\n",
    "    # using Euclidean distance to tracking each postion.\n",
    "    hands_center = get_tracking_index(hands_center, new_center, threed_points)\n",
    "    fingertips = get_tracking_index(fingertips, new_tips, threed_points)\n",
    "    \n",
    "#     print('tracking hand center: ', hands_center)\n",
    "#     print('tracking fingertips: ', fingertips)\n",
    "#     print('----------------------------')\n",
    "\n",
    "    if(draw_image is not None):\n",
    "        tracking_image = draw_image.copy()\n",
    "        hand_color = (255, 255, 0)\n",
    "        fingertip_color = (255, 255, 0)\n",
    "        text_size = 0.25\n",
    "        for i, h in enumerate(hands_center):\n",
    "            if(h[0] != -1):\n",
    "                hand_text = 'h_' + str(i)\n",
    "                pos = (int(hands_center[i][0]), int(hands_center[i][1]))\n",
    "                cv2.putText(img=tracking_image, text=hand_text, org=pos, fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=text_size, color=hand_color)\n",
    "        for j, f in enumerate(fingertips):\n",
    "            if(f[0] != -1):\n",
    "                finger_text = 'f_' + str(j)\n",
    "                pos = (int(fingertips[j][0]), int(fingertips[j][1]))\n",
    "                cv2.putText(img=tracking_image, text=finger_text, org=pos, fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=text_size, color=fingertip_color)\n",
    "\n",
    "    return hands_center, fingertips, tracking_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Touching Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingertips_touched_flag = np.zeros((10,1))\n",
    "def touching_detection(tips, hand_mask, depth_image, draw_image=None):\n",
    "    '''\n",
    "    by Yuan-Syun ye on 2019/06/17.\n",
    "    \n",
    "    To detect if the fingertips are touching or not, our algorithm analyzes a 7x7 patch centered on the fingertip's contour position.\n",
    "    Each patch of pixels centered on the fingertip's contour position. Each patch is split into S, the set of pixels within the hand + finger mask,\n",
    "    and T, the set of pixels outside the mask. The estimated height of the finger is then given by max(Zs|s C S) - min(Zt|t C T)\n",
    "    \n",
    "    To confirm contact with the surface, the algorithm applies a simple pair of hysteresis thresholds - a fingertip is declared as touching\n",
    "    the surface if the smoothed fingertip height descends below 10 mm, and declared to have left the surface if its height laster ascends past 15 mm.\n",
    "    '''\n",
    "    global fingertips_touched_flag\n",
    "    kernal_size = 7\n",
    "    touch_height = 0.01\n",
    "    untouch_height = 0.015\n",
    "    \n",
    "    max_width, max_height =  hand_mask.shape\n",
    "#     print('max width: %d, height: %d'%(max_width, max_height))\n",
    "#     print('test access: %d'%(hand_mask[170, 223]))\n",
    "    \n",
    "    for index, tip in enumerate(tips):\n",
    "        \n",
    "        # this tip is not tracking\n",
    "        if(tip[0] == -1):\n",
    "            fingertips_touched_flag[index] = False\n",
    "            continue\n",
    "            \n",
    "        # the min hight within the hand+finger mask\n",
    "        Zs = (0,0)\n",
    "        tip_height = 999\n",
    "        \n",
    "        # the max height outside the mask.\n",
    "        Zt = (0,0)\n",
    "        surface_height = -999\n",
    "\n",
    "#         print ('tip[%d] = (%d, %d)' % (i, tip[0], tip[1]))\n",
    "        for h in range(-math.floor(kernal_size/2), math.floor(kernal_size/2), 1):\n",
    "            for w in range(-math.floor(kernal_size/2), math.floor(kernal_size/2), 1):\n",
    "                (u, v) = (tip[0]+w, tip[1]+h)\n",
    "#                 print('check range: (%d, %d)'%(u, v))      \n",
    "\n",
    "                # check the bounder\n",
    "                if(u < 0 or u >= max_width):\n",
    "                    continue\n",
    "                if(v < 0 or v >= max_height):\n",
    "                    continue\n",
    "\n",
    "                if (hand_mask[u, v] == True):\n",
    "                    if(depth_image[u, v] < tip_height):\n",
    "                        Zs = (u, v)\n",
    "                        tip_height = depth_image[u,v]\n",
    "                else:\n",
    "                    if(depth_image[u, v] > surface_height):\n",
    "                        Zt = (u,v )\n",
    "                        surface_height = depth_image[u,v]\n",
    "            if((tip_height - surface_height) < touch_height):\n",
    "                fingertips_touched_flag[index] = True\n",
    "            if((tip_height - surface_height) > untouch_height):\n",
    "                fingertips_touched_flag[index] = False\n",
    "#     print(fingertips_touched_flag)\n",
    "\n",
    "    # debug image\n",
    "    if(draw_image is not None):\n",
    "        touched_image = draw_image.copy()\n",
    "        touched_text = \"touched\"\n",
    "        text_size = 0.5\n",
    "        touched_color = (0, 0, 255)\n",
    "        for i, touched in enumerate(fingertips_touched_flag):\n",
    "            if(touched == True):\n",
    "                pos = (tips[i][0], tips[i][1])\n",
    "                cv2.circle(touched_image, pos, 5 , touched_color , 3)\n",
    "                cv2.putText(img=touched_image, text=touched_text, org=pos, fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=text_size, color=touched_color)\n",
    "    return fingertips_touched_flag, draw_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main ():\n",
    "    parser = argparse.ArgumentParser(usage=__doc__)\n",
    "    add_camera_opener_options(parser)\n",
    "    parser.add_argument(\"--seconds\", type=int, default=15, help=\"duration to capture data\")\n",
    "    options = parser.parse_args(args=['--rrf','456.rrf','--seconds', '5'])\n",
    "#     options = parser.parse_args(args=['--seconds', '5'])\n",
    "    opener = CameraOpener(options)\n",
    "    cam = opener.open_camera()\n",
    "\n",
    "    print_camera_info (cam)\n",
    "    print(\"isConnected\", cam.isConnected())\n",
    "    print(\"getFrameRate\", cam.getFrameRate())\n",
    "    print(cam.getFilterLevel())\n",
    "\n",
    "    z_queue = queue.Queue()\n",
    "    gray_queue = queue.Queue()\n",
    "    points3D_queue = queue.Queue()\n",
    "    ConfidenceIndex_queue = queue.Queue()\n",
    "    Confidence_queue = queue.Queue()\n",
    "    l = MyListener(z_queue,gray_queue,points3D_queue,ConfidenceIndex_queue,Confidence_queue)\n",
    "\n",
    "    cam.registerDataListener(l)\n",
    "    cam.startCapture()\n",
    "\n",
    "    process_event(z_queue, gray_queue, points3D_queue, ConfidenceIndex_queue, Confidence_queue, painter=l, seconds=150)\n",
    "\n",
    "    cam.stopCapture()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "if (__name__ == \"__main__\"):\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#show plane edge\n",
    "test = np.zeros((171,224), np.uint8)\n",
    "l = 30\n",
    "test[l:171-l,l:224-l] = 1\n",
    "plt.imshow(test),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 7\n",
    "import math\n",
    "for i in range(-math.floor(size/2), math.floor(size/2), 1):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

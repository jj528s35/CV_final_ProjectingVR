{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import roypy\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time\n",
    "import queue\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "\n",
    "import tracking\n",
    "import touched_detection\n",
    "from PIL import Image, ImageDraw\n",
    "from sample_camera_info import print_camera_info\n",
    "from roypy_sample_utils import CameraOpener, add_camera_opener_options\n",
    "\n",
    "# 調整np.array輸出格式\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener(roypy.IDepthDataListener):\n",
    "\n",
    "    def __init__(self, z_queue, gray_queue, points3D_queue, ConfidenceIndex_queue, Confidence_queue, undistortImage=False):\n",
    "        super(MyListener, self).__init__()\n",
    "        self.z_queue = z_queue\n",
    "        self.gray_queue = gray_queue\n",
    "        self.points3D_queue = points3D_queue\n",
    "        self.ConfidenceIndex_queue = ConfidenceIndex_queue\n",
    "        self.Confidence_queue = Confidence_queue\n",
    "        self.undistortImage = undistortImage\n",
    "        self.cameraMatrix = None\n",
    "        self.distortionCoefficients = None\n",
    "        self.First = True\n",
    "\n",
    "    def onNewData(self, data):\n",
    "        s_time = time.time()\n",
    "        zvalues = []\n",
    "        xvalues = []\n",
    "        yvalues = []\n",
    "        grayvalues = []\n",
    "        points3D = []\n",
    "        ConfidenceIndexvalues = [] # whether the pixel measured a valid 3D value\n",
    "        Confidencevalue = []\n",
    "        for i in range(data.getNumPoints()):\n",
    "            zvalues.append(data.getZ(i))\n",
    "            xvalues.append(data.getX(i))\n",
    "            yvalues.append(data.getY(i))\n",
    "            grayvalues.append(data.getGrayValue(i))\n",
    "            \n",
    "#             Confidencevalue.append(data.getDepthConfidence(i))\n",
    "            if self.First == True:\n",
    "                if data.getDepthConfidence(i) > 0:\n",
    "                    ConfidenceIndexvalues.append(i)\n",
    "            \n",
    "        zarray = np.asarray(zvalues)\n",
    "        z = zarray.reshape (-1, data.width)        \n",
    "        self.z_queue.put(z)\n",
    "        \n",
    "        xarray = np.asarray(xvalues)\n",
    "        x = xarray.reshape (-1, data.width)\n",
    "        \n",
    "        yarray = np.asarray(yvalues)\n",
    "        y = yarray.reshape (-1, data.width)\n",
    "        \n",
    "        points3D = np.dstack((x,y,z))\n",
    "        self.points3D_queue.put(points3D)\n",
    "        \n",
    "        \n",
    "        grayarray = np.asarray(grayvalues)\n",
    "        q = grayarray.reshape (-1, data.width)        \n",
    "        self.gray_queue.put(q)\n",
    "        \n",
    "#         Confidencearray = np.asarray(Confidencevalue)\n",
    "#         Confidence = Confidencearray.reshape (-1, data.width)\n",
    "#         self.Confidence_queue.put(Confidence)\n",
    "        #ConfidenceIndex_queue\n",
    "        if self.First == True:\n",
    "            ConfidenceIndex = np.asarray(ConfidenceIndexvalues)\n",
    "            self.ConfidenceIndex_queue.put(ConfidenceIndex)\n",
    "        \n",
    "        print('queue: %.4f'%(time.time() - s_time))\n",
    "\n",
    "    def paint(self, data, name, isGray = False, cv2_show = False):\n",
    "        \"\"\"\n",
    "        Called in the main thread, with data containing one of the items that was added to the queue in onNewData\n",
    "        :param data:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if cv2_show == True: \n",
    "            cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "            cv2.resizeWindow(name, 224*2,171*2)\n",
    "            cv2.imshow(name, data)\n",
    "        else:\n",
    "            # create a figure and show the raw data\n",
    "            plt.figure(1)\n",
    "            if isGray == False:\n",
    "                plt.imshow(data),plt.title(name),plt.axis('off')\n",
    "            else: \n",
    "                plt.imshow(data,plt.cm.gray),plt.title(name),plt.axis('off')\n",
    "\n",
    "            plt.show(block=False)\n",
    "            plt.draw()\n",
    "\n",
    "            # this pause is needed to ensure the drawing for some backends\n",
    "            plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyListener(roypy.IDepthDataListener):\n",
    "\n",
    "#     def __init__(self, z_queue, gray_queue, points3D_queue, ConfidenceIndex_queue, Confidence_queue, undistortImage=False):\n",
    "#         super(MyListener, self).__init__()\n",
    "#         self.z_queue = z_queue\n",
    "#         self.gray_queue = gray_queue\n",
    "#         self.points3D_queue = points3D_queue\n",
    "#         self.ConfidenceIndex_queue = ConfidenceIndex_queue\n",
    "#         self.Confidence_queue = Confidence_queue\n",
    "#         self.undistortImage = undistortImage\n",
    "#         self.cameraMatrix = None\n",
    "#         self.distortionCoefficients = None\n",
    "#         self.First = True\n",
    "\n",
    "#     def onNewData(self, data):\n",
    "#         s_time = time.time()\n",
    "#         zvalues = []\n",
    "#         xvalues = []\n",
    "#         yvalues = []\n",
    "#         grayvalues = []\n",
    "#         points3D = []\n",
    "#         ConfidenceIndexvalues = [] # whether the pixel measured a valid 3D value\n",
    "#         Confidencevalue = []\n",
    "        \n",
    "#         points = data.points()\n",
    "        \n",
    "#         for i in range(data.getNumPoints()):\n",
    "#             zvalues.append(points[i].z)\n",
    "#             xvalues.append(points[i].x)\n",
    "#             yvalues.append(points[i].y)\n",
    "#             grayvalues.append(points[i].grayValue)\n",
    "            \n",
    "# #             Confidencevalue.append(data.getDepthConfidence(i))\n",
    "#             if self.First == True:\n",
    "#                 if points[i].depthConfidence > 0:\n",
    "#                     ConfidenceIndexvalues.append(i)\n",
    "            \n",
    "#         zarray = np.asarray(zvalues)\n",
    "#         z = zarray.reshape (-1, data.width)        \n",
    "#         self.z_queue.put(z)\n",
    "        \n",
    "#         xarray = np.asarray(xvalues)\n",
    "#         x = xarray.reshape (-1, data.width)\n",
    "        \n",
    "#         yarray = np.asarray(yvalues)\n",
    "#         y = yarray.reshape (-1, data.width)\n",
    "        \n",
    "#         points3D = np.dstack((x,y,z))\n",
    "#         self.points3D_queue.put(points3D)\n",
    "        \n",
    "        \n",
    "#         grayarray = np.asarray(grayvalues)\n",
    "#         q = grayarray.reshape (-1, data.width)        \n",
    "#         self.gray_queue.put(q)\n",
    "        \n",
    "# #         Confidencearray = np.asarray(Confidencevalue)\n",
    "# #         Confidence = Confidencearray.reshape (-1, data.width)\n",
    "# #         self.Confidence_queue.put(Confidence)\n",
    "#         #ConfidenceIndex_queue\n",
    "#         if self.First == True:\n",
    "#             ConfidenceIndex = np.asarray(ConfidenceIndexvalues)\n",
    "#             self.ConfidenceIndex_queue.put(ConfidenceIndex)\n",
    "            \n",
    "#         print('queue: %.4f'%(time.time() - s_time))\n",
    "# #         self.First = False\n",
    "\n",
    "#     def paint(self, data, name, isGray = False, cv2_show = False):\n",
    "#         \"\"\"\n",
    "#         Called in the main thread, with data containing one of the items that was added to the queue in onNewData\n",
    "#         :param data:\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         if cv2_show == True: \n",
    "#             cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "#             cv2.resizeWindow(name, 224*2,171*2)\n",
    "#             cv2.imshow(name, data)\n",
    "#         else:\n",
    "#             # create a figure and show the raw data\n",
    "#             plt.figure(1)\n",
    "#             if isGray == False:\n",
    "#                 plt.imshow(data),plt.title(name),plt.axis('off')\n",
    "#             else: \n",
    "#                 plt.imshow(data,plt.cm.gray),plt.title(name),plt.axis('off')\n",
    "\n",
    "#             plt.show(block=False)\n",
    "#             plt.draw()\n",
    "\n",
    "#             # this pause is needed to ensure the drawing for some backends\n",
    "#             plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracker Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_event(z_queue, gray_queue, points3D_queue, ConfidenceIndex_queue, Confidence_queue, painter=None, seconds=150):\n",
    "    First = True\n",
    "    timeout = .5\n",
    "    wait_data_flag = False\n",
    "    capture_frame = 45\n",
    "    frame = 0\n",
    "    t_end = time.time() + seconds # create a loop that will rsecondsthe given amount of time\n",
    "    start_time = time.time()\n",
    "    receive_time = 1\n",
    "    num_of_frames = 0\n",
    "    while time.time() < t_end:\n",
    "        # Press Q on keyboard to exit \n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        try:\n",
    "            # try to retrieve an item from the queue\n",
    "            # this will block until an item can be retrieved\n",
    "            # or the timeout of 1 second is hit\n",
    "            zImage = z_queue.get(wait_data_flag, timeout) if z_queue else None\n",
    "            grayImage_int32 = gray_queue.get(wait_data_flag, timeout) if gray_queue else None\n",
    "            points3D = points3D_queue.get(wait_data_flag, timeout) if points3D_queue else None\n",
    "            if First == True:\n",
    "                ConfidenceIndex = ConfidenceIndex_queue.get(wait_data_flag, timeout) if ConfidenceIndex_queue else None\n",
    "#             Confidence = Confidence_queue.get(wait_data_flag, timeout) if Confidence_queue else None\n",
    "        except queue.Empty:\n",
    "            # this will be thrown when the timeout is hit\n",
    "            continue\n",
    "        else:\n",
    "            frame = frame + 1\n",
    "            num_of_frames = num_of_frames +1\n",
    "            if (frame > capture_frame):\n",
    "                # estimated time\n",
    "                receive_time = (time.time() - start_time)\n",
    "                frame = 0\n",
    "                start_time = time.time()\n",
    "            if(receive_time != 0):\n",
    "                size = zImage.shape\n",
    "                input_fps = capture_frame\n",
    "                cv2.putText(img=zImage, text=('fps=%.1f'%(input_fps/receive_time)), org=(0, size[1]-75), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.25, color=(255,255,255))\n",
    "            cv2.imshow('zImage', zImage)\n",
    "            \n",
    "            if First == True:\n",
    "                #RANSAM to get surface plane\n",
    "                surface_plane, depthImg, plane_mask = RANSAM(points3D, ConfidenceIndex, ransac_iteration = 500, inliner_threshold = 0.01)\n",
    "                First = False\n",
    "                painter.First = False\n",
    "                print(\"firstly RANSAM\")\n",
    "                fs_time = time.time()\n",
    "            else:\n",
    "                #\n",
    "                cs_time = time.time()\n",
    "                s_time = time.time()\n",
    "                depthImg = get_depth_map(points3D, surface_plane)\n",
    "#                 print('depth: %.4f'%(time.time() - s_time))\n",
    "                \n",
    "                #Canny edge map(infrared image) + threshold based edge map(depth image)\n",
    "#                 s_time = time.time()\n",
    "                Cannyedges, Threshold_based_edge, Edge_map, grayImage = get_edge_map(grayImage_int32, depthImg)\n",
    "#                 print('get edge map: %.4f s'%(time.time() - s_time))\n",
    "                \n",
    "                #Get hight region by Hight and record its position\n",
    "#                 s_time = time.time()\n",
    "                High_region_Image, high_region_list = get_high_region(depthImg)\n",
    "#                 print('get hight region: %.4f s'%(time.time() - s_time))\n",
    "                \n",
    "                #Get Hand mask by Flood fill from high region position with Edge map\n",
    "#                 s_time = time.time()\n",
    "                Hand_mask_Image = get_Hand_mask(Edge_map, high_region_list, High_region_Image)\n",
    "#                 print('get hand mask: %.4f s'%(time.time() - s_time))\n",
    "                \n",
    "                #\n",
    "#                 s_time = time.time()\n",
    "                cnt, contours_image, hand_center, fingertips = find_fingertip(Hand_mask_Image,True)\n",
    "#                 print('find fingertip: %.4f s'%(time.time() - s_time))\n",
    "                \n",
    "                # tracking user hand and fingertips\n",
    "#                 s_time = time.time()\n",
    "                hands_hand, fingertips_pos, tracking_iamge = tracking.hand_tracking(hand_center, fingertips, points3D, contours_image)\n",
    "#                 print('hand tracking: %.4f s'%(time.time() - s_time))\n",
    "                \n",
    "                # detecte fingers whenther touching the surface\n",
    "#                 s_time = time.time()\n",
    "                touched_flag, touching_detection_image = touched_detection.touching_detection(fingertips_pos, Hand_mask_Image, depthImg, contours_image)\n",
    "#                 print('touched detection: %.4f s'%(time.time() - s_time))\n",
    "                \n",
    "                print('total time: %.4f s'%(time.time() - cs_time), 'fps: %.4f s'%(1/(time.time() - fs_time)))\n",
    "                print()\n",
    "                fs_time = time.time()\n",
    "                \n",
    "                #Show original image and result image\n",
    "                painter.paint(grayImage*15,'Gray Image',True, True)\n",
    "#                 painter.paint(depthImg,'Depth', False)\n",
    "#                 painter.paint(Cannyedges,'Canny Edges',True)\n",
    "#                 painter.paint(Threshold_based_edge,'Threshold_based Edge',True)\n",
    "#                 painter.paint(Edge_map,'Edge map',True)\n",
    "#                 painter.paint(High_region_Image,'High region Image',True)\n",
    "#                 painter.paint(Hand_mask_Image,'Hand mask Image')\n",
    "#                 painter.paint(contours_image,'Contours Image',True)\n",
    "                painter.paint(tracking_iamge,'tracking Image',False, True)\n",
    "                painter.paint(touching_detection_image,'touched Image', False, True)\n",
    "#                 painter.paint(touching_detection_image,'touched Image', False)\n",
    "            \n",
    "    print(num_of_frames)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANSAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dis_pt2plane(pts, a, b, c, d):\n",
    "    \"\"\"\n",
    "    Compute the distance from points to the plane\n",
    "    \"\"\"\n",
    "    normal = math.sqrt(a*a+b*b+c*c)\n",
    "    if normal == 0:\n",
    "        normal = 1\n",
    "    \n",
    "    v = np.array([a,b,c])\n",
    "    dis = abs(np.dot(pts,v.T)+d)/normal\n",
    "    return dis\n",
    "\n",
    "def get_Plane(sampts):\n",
    "    \"\"\"\n",
    "    Compute the equation of the plane\n",
    "    \"\"\"\n",
    "    p1 = sampts[0]\n",
    "    p2 = sampts[1]\n",
    "    p3 = sampts[2]\n",
    "    \n",
    "    a = ( (p2[1]-p1[1])*(p3[2]-p1[2])-(p2[2]-p1[2])*(p3[1]-p1[1]) )\n",
    "    b = ( (p2[2]-p1[2])*(p3[0]-p1[0])-(p2[0]-p1[0])*(p3[2]-p1[2]) )\n",
    "    c = ( (p2[0]-p1[0])*(p3[1]-p1[1])-(p2[1]-p1[1])*(p3[0]-p1[0]) )\n",
    "    d = ( 0-(a*p1[0]+b*p1[1]+c*p1[2]) )\n",
    "    \n",
    "    return a,b,c,d\n",
    "\n",
    "def Random3points(points3D, ConfidenceIndex):\n",
    "    \"\"\"\n",
    "    Random choose 3 Confidence points\n",
    "    \"\"\"\n",
    "    sample_number = 3\n",
    "    sample_point_index = random.sample(range(ConfidenceIndex.shape[0]), sample_number)\n",
    "    sample_points = np.zeros((sample_number,3))\n",
    "    for i in range(sample_number):\n",
    "        Confidence_point_index = sample_point_index[i]\n",
    "        index = ConfidenceIndex[Confidence_point_index]\n",
    "        y = index // points3D.shape[1]\n",
    "        x = index % points3D.shape[1]\n",
    "        sample_points[i] = points3D[y][x]\n",
    "    return sample_points\n",
    "\n",
    "# def Random3points(points3D):\n",
    "#     sample_number = 3\n",
    "#     sample_point_index = random.sample(range(points3D.shape[0]*points3D.shape[1]), sample_number)\n",
    "#     sample_points = np.zeros((sample_number,3))\n",
    "#     for i in range(sample_number):\n",
    "#         index = sample_point_index[i]\n",
    "#         y = index // points3D.shape[1]\n",
    "#         x = index % points3D.shape[1]\n",
    "#         sample_points[i] = points3D[y][x]\n",
    "#     return sample_points\n",
    "\n",
    "def get_inliner_num(points3D,a,b,c,d,inliner_threshold):\n",
    "    \"\"\"\n",
    "    Compute the liner points which distance to plane < threshold\n",
    "    Also get distance from points to the plane (new Depth Image which re-project depth pixels in surface plane)\n",
    "    \"\"\"\n",
    "    inliner_num = 0\n",
    "    \n",
    "    dist = Dis_pt2plane(points3D,a,b,c,d)\n",
    "    inliner_mask = dist < inliner_threshold\n",
    "    inliner_num = np.sum(inliner_mask)\n",
    "    return inliner_num, inliner_mask, dist\n",
    "\n",
    "def RANSAM(points3D, ConfidenceIndex, ransac_iteration = 1000, inliner_threshold = 0.01):\n",
    "    best_inlinernum = -1\n",
    "    best_inlinernum = 0\n",
    "    best_plane = np.zeros((1,4))\n",
    "    best_depthImage = np.zeros((points3D.shape[0],points3D.shape[1]))\n",
    "    best_plane_mask = np.zeros((points3D.shape[0],points3D.shape[1]))\n",
    "#     best_sampts = np.zeros((3,3))\n",
    "    \n",
    "#     print(points3D.shape,points3D[80:90,110])\n",
    "    for i in range(ransac_iteration):\n",
    "        sampts = Random3points(points3D, ConfidenceIndex)\n",
    "        a,b,c,d = get_Plane(sampts)\n",
    "        \n",
    "        inliner_num, inliner_mask, depthImage = get_inliner_num(points3D,a,b,c,d,inliner_threshold)\n",
    "        if(inliner_num > best_inlinernum):\n",
    "            best_inlinernum = inliner_num\n",
    "            best_plane = np.array([a,b,c,d])\n",
    "            best_plane_mask = inliner_mask\n",
    "            best_depthImage = depthImage\n",
    "#             best_sampts = sampts\n",
    "            \n",
    "    print(\"Inliner Number\\n\", best_inlinernum)\n",
    "    print(\"Inliner plane\\n\", best_plane)\n",
    "    return best_plane, best_depthImage, best_plane_mask\n",
    "\n",
    "# ptset = np.array(([0, 0, 0],\n",
    "#             [1, 2, 0],\n",
    "#             [2, 2, 0]))\n",
    "# a,b,c,d = get_Plane(ptset)\n",
    "# pts = np.zeros((2,2,3))\n",
    "# pts[0,0] = np.array([0, 0, 1])\n",
    "# pts[0,1] = np.array([0, 0, 2])\n",
    "# pts[1,0] = np.array([0, 0, 3])\n",
    "# pts[1,1] = np.array([0, 0, 4])\n",
    "# z = Dis_pt2plane(pts,a,b,c,d)\n",
    "# print(z,z.shape)\n",
    "# get_inliner_num(pts,a,b,c,d,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_map(points3D,plane):\n",
    "    \"\"\"\n",
    "    Compute the liner points which distance to plane < threshold\n",
    "    Also get distance from points to the plane (new Depth Image which re-project depth pixels in surface plane)\n",
    "    \"\"\"\n",
    "    dist = Dis_pt2plane(points3D,plane[0],plane[1],plane[2],plane[3])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_map(grayImage,depthImage):\n",
    "    \"\"\"\n",
    "    Canny Edge map\n",
    "    turn grayImg from int32 to int8\n",
    "    blur the grayImg then do Canny Edge\n",
    "    \"\"\"\n",
    "    low_threshold = 2\n",
    "    high_threshold = 10\n",
    "    grayimg_int8 = cv2.convertScaleAbs(grayImage, alpha=(255.0/65535.0))\n",
    "    \n",
    "    kernel_size = 3\n",
    "    blur_gray = cv2.GaussianBlur(grayimg_int8,(kernel_size, kernel_size), 0)\n",
    "    Cannyedges = cv2.Canny(grayimg_int8, low_threshold, high_threshold)#blur_gray\n",
    "    \n",
    "    \"\"\"\n",
    "    Threshold based Edge map\n",
    "    if depth between the pixel and its nearby pixels > near_depth_threshold, then labeled it\n",
    "    \"\"\"\n",
    "    s_time = time.time()\n",
    "    near_depth_threshold = 0.05\n",
    "    Threshold_based_edge = np.zeros((depthImage.shape[0],depthImage.shape[1]))\n",
    "    \n",
    "    h = depthImage.shape[0]\n",
    "    w = depthImage.shape[1]\n",
    "    depth_img_transform = np.zeros((h+1,w+1))\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    #check left up depth threshold\n",
    "    depth_img_transform[1:h+1,1:w+1] = depthImage\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check up depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[1:h+1,:w] = depthImage\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:depthImage.shape[0],:depthImage.shape[1]]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check Right up depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[1:h+1,:w-1] = depthImage[:,1:w]\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check Left depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[:h,1:w+1] = depthImage\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check Right depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[:h,:w-1] = depthImage[:,1:w]\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check Left down depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[:h-1,1:w+1] = depthImage[1:h,:]\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check down depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[:h-1,:w] = depthImage[1:h,:]\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    #check Right down depth threshold\n",
    "    depth_img_transform[:h,:w] = depthImage\n",
    "    depth_img_transform[:h-1,:w-1] = depthImage[1:h,1:w]\n",
    "    check_depth_threshold = abs(depthImage - depth_img_transform[:h,:w]) > near_depth_threshold\n",
    "    Threshold_based_edge = np.logical_or(Threshold_based_edge, check_depth_threshold)\n",
    "    \n",
    "    \n",
    "#     print('*get threshold edge: %.4f s'%(time.time()-s_time))\n",
    "    \"\"\"\n",
    "    Merge Canny Edge map and Threshold based Edge map\n",
    "    \"\"\"\n",
    "    Edge_map = np.logical_or(Cannyedges,Threshold_based_edge)\n",
    "    \n",
    "    return Cannyedges,Threshold_based_edge, Edge_map, blur_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find High Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_region(depthImage):\n",
    "    \"\"\"\n",
    "    Define plane edge\n",
    "    High region : > 0.04 \n",
    "    ==> Flood fill mask : if pixels value > 0.04, then its value of mask image = 0 \n",
    "    ==> mask = depthImage < 0.04\n",
    "    \n",
    "    Next, reject the region which dose not connet with plane edge and record its position\n",
    "    ==>Just do Flood fill around the plane edge\n",
    "    \"\"\"\n",
    "    h, w = depthImage.shape[:2]\n",
    "    high_region_mask = np.ones((h+2,w+2), np.uint8)\n",
    "    high_region_mask[1:h+1,1:w+1] = depthImage < 0.04 # > 0.04 False == 0, Flood fill will fill pixels with 0\n",
    "    resultImg = np.zeros((h,w), np.uint8)\n",
    "    \n",
    "    #define plane edge\n",
    "    plane_edge = 15#25\n",
    "    \n",
    "    x1 = plane_edge\n",
    "    x2 = w - plane_edge\n",
    "    y1 = plane_edge\n",
    "    y2 = h - plane_edge\n",
    "    \n",
    "    high_list = []\n",
    "    \n",
    "    for y in range(plane_edge, y2):\n",
    "        if high_region_mask[y+1,x1+1] == 0 and resultImg[y,x1] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x1, y),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x1,y))\n",
    "            \n",
    "        if high_region_mask[y+1,x2+1] == 0 and resultImg[y,x2] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x2, y),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x2,y))\n",
    "            \n",
    "    for x in range(plane_edge, x2):\n",
    "        if high_region_mask[y1+1,x+1] == 0 and resultImg[y1,x] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x, y1),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x, y1))\n",
    "            \n",
    "        if high_region_mask[y2+1,x+1] == 0 and resultImg[y2,x] != True:\n",
    "            cv2.floodFill(resultImg, high_region_mask, (x, y2),True, cv2.FLOODFILL_MASK_ONLY)\n",
    "            high_list.append((x, y2))\n",
    "            \n",
    "            \n",
    "#     (_, cnts, _) = cv2.findContours(resultImg.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "#     maxArea = 0\n",
    "#     hull = None\n",
    "#     for i in range(len(cnts)):\n",
    "#         area = cv2.contourArea(cnts[i])\n",
    "#         if area > maxArea:\n",
    "#             maxArea = area\n",
    "#             hull = cv2.convexHull(cnts[i])\n",
    "    \n",
    "#     cx, cy = (0,0)\n",
    "#     if hull is not None : \n",
    "#         # get centroid from hand, then Draw the center and Hull_Convex\n",
    "#         M = cv2.moments(hull)\n",
    "#         cx = int(M[\"m10\"]/M[\"m00\"])\n",
    "#         cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "#         high_list.append((cx,cy))\n",
    "    \n",
    "    return resultImg, high_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Hand_mask(Edge_map, high_list, High_region_Image):\n",
    "    \"\"\"\n",
    "    Flood fill from high region position and stop when reach edge\n",
    "    Only fill in the hight region mask \n",
    "    ==> Prevent flood fill from seed which filled region does not the hight region\n",
    "    \"\"\"\n",
    "    h, w = Edge_map.shape[:2]\n",
    "    \n",
    "    resultImg = Edge_map.copy()\n",
    "    resultImg.dtype = 'uint8'\n",
    "    mask = np.zeros((h+2,w+2), np.uint8)\n",
    "    mask1 = np.ones((h+2,w+2), np.uint8)\n",
    "    mask1[1:h+1,1:w+1] = High_region_Image == False\n",
    "\n",
    "    for i in range(len(high_list)):\n",
    "        cv2.floodFill(resultImg, mask1, high_list[i],True,cv2.FLOODFILL_FIXED_RANGE)\n",
    "    \n",
    "    resultImg = resultImg - Edge_map\n",
    "    \n",
    "    return resultImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Fingertip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fingertip(hand_mask, debug = False):\n",
    "    '''\n",
    "        return: \n",
    "        @cnt: contours\n",
    "    '''\n",
    "    fingertips = []\n",
    "    kernel_size = 7\n",
    "    \n",
    "    #Smooth the mask and find the contours\n",
    "    smooth_mask = cv2.GaussianBlur(hand_mask,(kernel_size, kernel_size), 0)\n",
    "    (_, cnts, _) = cv2.findContours(smooth_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #convert the result image into RGB image\n",
    "    contours_image = cv2.convertScaleAbs(smooth_mask, alpha=(255))\n",
    "    contours_image = cv2.cvtColor(contours_image, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Find the contour with max area\n",
    "    maxArea = 0\n",
    "    hull = None\n",
    "    for i in range(len(cnts)):\n",
    "        area = cv2.contourArea(cnts[i])\n",
    "        if area > maxArea:\n",
    "            maxArea = area\n",
    "            hull = cv2.convexHull(cnts[i])\n",
    "            Contours = cnts[i]\n",
    "    \n",
    "    cx, cy = (0,0)\n",
    "    if hull is not None : \n",
    "        # get centroid from hand, then Draw the center and Hull_Convex\n",
    "        M = cv2.moments(hull)\n",
    "        cx = int(M[\"m10\"]/M[\"m00\"])\n",
    "        cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "        if(debug == True):\n",
    "            cv2.circle(contours_image, (cx, cy), 5, (0,0,255), 3)\n",
    "        cv2.drawContours(contours_image, [Contours], -1, (255,0,0), 2)\n",
    "        \n",
    "        #Find the Fingertips\n",
    "#         start = time.time()\n",
    "        fingertips, contours_image = find_fingertips_by_dot(Contours, hull, contours_image,(cx, cy), debug)\n",
    "#         print('finger: %.4f'%(time.time() - start))\n",
    "\n",
    "    return cnts, contours_image, (cx, cy), np.asarray(fingertips, dtype=np.int32)\n",
    "\n",
    "\n",
    "def find_fingertips_by_dot(Contours, hull, contours_image, center, debug=False):\n",
    "    fingertips = []\n",
    "    skip = 4 # 4 ==> 點少但無誤判\n",
    "    Convex = (0,0)\n",
    "    post_dot = 20\n",
    "    threshold = 8\n",
    "    Convex_threshold = 1\n",
    "    Dot_threshold = 20\n",
    "    first = True\n",
    "    for i in range(skip, len(Contours)-skip):\n",
    "        p = Contours[i-skip]\n",
    "        q = Contours[i]\n",
    "        r = Contours[i+skip]\n",
    "\n",
    "        dot = np.dot(p-q,(r-q).T)\n",
    "        if (dot < Dot_threshold and dot > -Dot_threshold):\n",
    "            points = (q[0,0],q[0,1])\n",
    "            if first == True:\n",
    "                Convex = points\n",
    "                s_point = 0\n",
    "            IsnotEdge = points[0]!=0 and points[1]!=0 and points[0]!=contours_image.shape[1] and points[1]!=contours_image.shape[0]\n",
    "            IsConvex, s_point = Points_is_convex(hull, points, Convex_threshold, s_point)\n",
    "            Near_Labeled = abs(Convex[0] - points[0]) > threshold and abs(Convex[1] - points[1]) > threshold\n",
    "            #if the point is in the convex list and haven't be labeled, then add it to Fingertip list\n",
    "            if IsConvex and IsnotEdge:\n",
    "                if Near_Labeled or first:\n",
    "                    fingertips.append(points)\n",
    "                    first = False\n",
    "                elif dot < post_dot:#若在附近，則取曲率較小的點\n",
    "                    fingertips[-1] = points\n",
    "                Convex = points\n",
    "                post_dot = dot\n",
    "                    \n",
    "    if(debug==True):\n",
    "        for i in range(len(fingertips)):\n",
    "            cv2.circle(contours_image, fingertips[i], 5 , (0,255,0) , 3)\n",
    "\n",
    "    return fingertips, contours_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cotour Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Points_is_convex_all(hull, points, threshold):\n",
    "#     label = False\n",
    "#     label_hull = hull.copy()\n",
    "#     for i in range(len(hull)):\n",
    "#         if abs(hull[i,0,0] - points[0]) <= threshold and abs(hull[i,0,1] - points[1]) <= threshold:\n",
    "#             label_hull[i,0] = (-1, -1)\n",
    "#             label = True\n",
    "#     return label, label_hull\n",
    "\n",
    "def Points_is_convex(hull, points, threshold, s_point):\n",
    "    label = False\n",
    "    label_hull = hull.copy()\n",
    "    for i in range(s_point, len(hull)):\n",
    "        if abs(hull[i,0,0] - points[0]) <= threshold and abs(hull[i,0,1] - points[1]) <= threshold:\n",
    "            label = True\n",
    "            if s_point - 5 >= 0:\n",
    "                s_point = i - 5\n",
    "            return label, s_point\n",
    "    return label, s_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_open_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##True: white 1  False: black 0\n",
    "# ptset = np.array(([False, False, False],\n",
    "#             [True, True, False],\n",
    "#             [False, True, False]))\n",
    "# plt.imshow(ptset,plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main ():\n",
    "    parser = argparse.ArgumentParser(usage=__doc__)\n",
    "    add_camera_opener_options(parser)\n",
    "    parser.add_argument(\"--seconds\", type=int, default=15, help=\"duration to capture data\")\n",
    "    \n",
    "    PlayBack = False\n",
    "    if PlayBack:\n",
    "        options = parser.parse_args(args=['--rrf','456.rrf','--seconds', '5'])\n",
    "    else:\n",
    "        options = parser.parse_args(args=['--seconds', '5'])\n",
    "    opener = CameraOpener(options)\n",
    "    cam = opener.open_camera()\n",
    "    \n",
    "    if PlayBack == False:\n",
    "        cam.setUseCase('MODE_5_45FPS_500')\n",
    "    print(\"FrameRate: \" ,cam.getFrameRate() ,\"CurrentUseCase: \" , cam.getCurrentUseCase())\n",
    "\n",
    "    print_camera_info (cam)\n",
    "    print(\"isConnected\", cam.isConnected())\n",
    "    print(\"getFrameRate\", cam.getFrameRate())\n",
    "    print(cam.getFilterLevel())\n",
    "\n",
    "    z_queue = queue.Queue()\n",
    "    gray_queue = queue.Queue()\n",
    "    points3D_queue = queue.Queue()\n",
    "    ConfidenceIndex_queue = queue.Queue()\n",
    "    Confidence_queue = queue.Queue()\n",
    "    l = MyListener(z_queue,gray_queue,points3D_queue,ConfidenceIndex_queue,Confidence_queue)\n",
    "\n",
    "    cam.registerDataListener(l)\n",
    "    cam.startCapture()\n",
    "\n",
    "    process_event(z_queue, gray_queue, points3D_queue, ConfidenceIndex_queue, Confidence_queue, painter=l, seconds=25)\n",
    "\n",
    "    cam.stopCapture()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    z_queue.queue.clear()\n",
    "    gray_queue.queue.clear()\n",
    "    points3D_queue.queue.clear()\n",
    "    ConfidenceIndex_queue.queue.clear()\n",
    "    Confidence_queue.queue.clear()\n",
    "    \n",
    "if (__name__ == \"__main__\"):\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#show plane edge\n",
    "test = np.zeros((171,224), np.uint8)\n",
    "l = 25\n",
    "test[l:171-l,l:224-l] = 1\n",
    "plt.imshow(test),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = (2, 2)\n",
    "kernal = 3\n",
    "x = np.zeros((5, 5))\n",
    "index = 0\n",
    "for h in range(0, 5):\n",
    "    for w in range(0, 5):\n",
    "        x[h, w] = index\n",
    "        index = index + 1\n",
    "bounding_sixe = math.floor(kernal/2)\n",
    "print(bounding_sixe)\n",
    "y = x[(u-bounding_sixe):(u+bounding_sixe+1), (v-bounding_sixe):(v+bounding_sixe+1)]\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "print(y.size)\n",
    "\n",
    "y = np.reshape(y, (y.size,-1))\n",
    "print(y)\n",
    "for i, test in enumerate(y):\n",
    "    print(i, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
